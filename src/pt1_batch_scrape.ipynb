{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celebrity Death Data (via Wikipedia)\n",
    "\n",
    "Creating a notebook to produce the dataset found at the [Kaggle Celebrity Deaths Page](https://www.kaggle.com/hugodarwood/celebrity-deaths).\n",
    "\n",
    "Attempting to replace the current dataset since it isn't complete (up-to-date) since there's no notebook to run to get up-to-date information and it has bad parses for some of the fields.\n",
    "\n",
    "**Current branch: Consolidating pipeline into one notebook while implementing batch queries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "use for writing out characters\n",
    "\"\"\"\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Get a copy of the default headers that requests would use\n",
    "headers = requests.utils.default_headers()\n",
    "\n",
    "# Update the headers with your custom ones\n",
    "# You don't have to worry about case-sensitivity with\n",
    "# the dictionary keys, because default_headers uses a custom\n",
    "# CaseInsensitiveDict implementation within requests' source code.\n",
    "headers.update(\n",
    "    {\n",
    "        'User-Agent': 'Celeb Death Scraper GZ',\n",
    "        'From': 'geordgez@gmail.com'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch query Wikipedia for monthly death pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2004 - 2016\n"
     ]
    }
   ],
   "source": [
    "# batch query limit is 50\n",
    "year_list = range(2004,2017)\n",
    "print 'Date range:', min(year_list), '-', max(year_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month_to_num = {\n",
    "    'January': 1,\n",
    "    'February': 2,\n",
    "    'March': 3,\n",
    "    'April': 4,\n",
    "    'May': 5,\n",
    "    'June': 6,\n",
    "    'July': 7,\n",
    "    'August': 8,\n",
    "    'September': 9,\n",
    "    'October': 10,\n",
    "    'November': 11,\n",
    "    'December': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max number of terms in one Wikipedia batch query\n",
    "api_qmax = 50\n",
    "\n",
    "# base URL for death summaries by month (and year)\n",
    "mo_yr_url_prefix = 'https://en.wikipedia.org/w/api.php?action=query&titles='\n",
    "mo_yr_url_suffix = '&prop=revisions&rvprop=content&format=json'\n",
    "\n",
    "# page sizes\n",
    "indiv_url_prefix = 'https://en.wikipedia.org/w/api.php?action=query&titles='\n",
    "indiv_url_suffix = '&prop=revisions&rvprop=size&format=json'\n",
    "\n",
    "# dates of birth and death\n",
    "base_bday_prefix = 'https://en.wikipedia.org/w/api.php?action=query&titles='\n",
    "base_bday_suffix = '&prop=revisions&rvprop=content&rvsection=0&format=json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions from previous version (master branch) that ran individual queries (instead of batch queries) in serial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desc_death_re = re.compile('(.*?),? ?((?:.+)*?). (?:.*?)?', re.DOTALL|re.MULTILINE)\n",
    "death_clean_no_url_re = re.compile('\\s?(.[^<]+)\\.? ?(?=<|\\[?http)(?:.*)?$')\n",
    "# death_clean_no_url_re = re.compile('\\s?\\w(.[^<])+[.]?(?:<|\\[?http)(?:.*)?$')\n",
    "\n",
    "\"\"\"\n",
    "Input: single text string to be processed\n",
    "\n",
    "Output: list of two string elements\n",
    "  - first string is description of person\n",
    "  - second string is cause of death \n",
    "  (last clause of input when more than one comma in field)\n",
    "  \n",
    "\"\"\"\n",
    "# bad design below: just remove urls and refs instead of extracting\n",
    "def get_description_and_death(text):\n",
    "    text_no_url = text\n",
    "    has_death_urls = death_clean_no_url_re.match(text)\n",
    "    \n",
    "    if has_death_urls:\n",
    "        text_no_url = has_death_urls.groups()[0]\n",
    "    else:\n",
    "        text_no_url = text\n",
    "        \n",
    "    text_parts = text_no_url.replace('=','').split(',')\n",
    "    num_parts = len(text_parts)\n",
    "    \n",
    "    if num_parts == 0:\n",
    "        return ['', '']\n",
    "    elif num_parts == 1:\n",
    "        return text_parts + ['']\n",
    "    elif text_parts[-1]:\n",
    "        if text_parts[-1][-1] == ')':\n",
    "            return ([','.join(text_parts)] + [''])\n",
    "        else:\n",
    "            return ([','.join(text_parts)] + [text_parts[-1]])\n",
    "    else:\n",
    "        return ([','.join(text_parts)] + [text_parts[-1]])\n",
    "    return text\n",
    "    \n",
    "\"\"\"\n",
    "Runs get_description_and_death() on the last element of a list\n",
    "\n",
    "Input: list of length n\n",
    "Output: list of length (n+1) with last element broken into description and death\n",
    "\"\"\"\n",
    "def add_description_and_death(entry_list):\n",
    "    return entry_list[:-1] + get_description_and_death(entry_list[-1])\n",
    "\n",
    "mo_yr_key_re = re.compile('(\\d+)_(\\d+).*?')\n",
    "name_age_re = re.compile('\\s?\\[\\[(.*?)\\]\\], (\\d+), (.+)?$', re.MULTILINE)\n",
    "\n",
    "\"\"\"\n",
    "Add the month and year as elements to an entry of type list\n",
    "\"\"\"\n",
    "def add_month_year_list(entry_list, mo_yr_key='_'):\n",
    "    base_list = mo_yr_key.split('_')\n",
    "    base_list.extend(entry_list)\n",
    "    return base_list\n",
    "\n",
    "\"\"\"\n",
    "Inputs: month-year key string, text entry string\n",
    "Outputs: list of length 4 of month, year, name, and age\n",
    "\"\"\"\n",
    "def parse_month_year_name_age(text_entry):\n",
    "    out_text = text_entry.replace('\\n', '')\n",
    "    yr_age_match = re.match(name_age_re, out_text)\n",
    "    if yr_age_match:\n",
    "        out_text = yr_age_match.groups()\n",
    "        return list(out_text)\n",
    "    return\n",
    "\n",
    "link_re = re.compile('\\[\\[([^\\|\\]]*)(?=\\||\\]\\])', re.DOTALL)\n",
    "link_all_re = re.compile('(\\[\\[(?:[^\\[\\]])+\\]\\])')\n",
    "\n",
    "\"\"\"\n",
    "Used to be messy, not anymore!\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Find wikitext links and convert them to the displayed text\n",
    "\n",
    "Input: text block\n",
    "Output: text block with wikitext URL text extracted and URL characters removed\n",
    "\"\"\"\n",
    "def extract_link_text(link_block):\n",
    "    link_present = link_re.search(link_block)\n",
    "    if link_present:\n",
    "        return link_present.groups()\n",
    "    return link_block\n",
    "\n",
    "\"\"\"\n",
    "Helper function for removing link text when using re.sub--identifies a wikitext URL\n",
    "\n",
    "Input: re.match object\n",
    "Output: text of matched object \n",
    "\"\"\"\n",
    "def link_only(matchobj):\n",
    "    cleaned_text = extract_link_text(matchobj.groups()[0])[0]\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Substitute all wikitext URL links with the display text for the URL\n",
    "\n",
    "Input: text block\n",
    "Output: text block with links removed\n",
    "\"\"\"\n",
    "def remove_link_text(text_block):\n",
    "    return re.sub(link_all_re, link_only, text_block)\n",
    "\n",
    "\n",
    "natl_pattern1 = re.compile(' ?((?:[A-Z][^\\s]+ ?)+) ', re.UNICODE)\n",
    "\n",
    "natl_unmatched_list = []\n",
    "\n",
    "def get_nationality_text(desc_text):\n",
    "    natl_match = natl_pattern1.match(desc_text.strip('['))\n",
    "    if natl_match:\n",
    "        return natl_match.groups()[0]\n",
    "    natl_unmatched_list.append(desc_text)\n",
    "    return desc_text\n",
    "    \n",
    "        \n",
    "# essentially does the same thing as extract_link_text\n",
    "def get_wiki_url(name_text):\n",
    "    return name_text.split('|')[0].strip('[').strip(']')\n",
    "\n",
    "\n",
    "def remove_end_period(text):\n",
    "    return re.sub('\\.$', '', re.sub('\\s$','',text))\n",
    "\n",
    "def remove_beginning_space(text):\n",
    "    return re.sub('^ +','',text)\n",
    "\n",
    "def clean_text(text):\n",
    "    if type(text) != str:\n",
    "        return text\n",
    "    \n",
    "    new_text = text\n",
    "    url_match = re.match(death_clean_no_url_re, text)\n",
    "    if url_match:\n",
    "        new_text = url_match.groups()[0]\n",
    "    return remove_beginning_space(\n",
    "        remove_end_period(\n",
    "            remove_link_text(new_text)\n",
    "        ).replace('[','').replace(']','')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New functions in this branch/notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert Wikipedia 'Deaths in (str: month) (int: year)' titles into '(int: month)_(int: year)'\n",
    "\"\"\"\n",
    "date_eol_re = re.compile('([A-Z][a-z]+) (\\d{4})$')\n",
    "\n",
    "def month_str2key(month_str):\n",
    "    date_eol = re.search(date_eol_re, month_str)\n",
    "    if date_eol:\n",
    "        date_parts = date_eol.groups()\n",
    "        month_num = str(month_to_num[date_parts[0]])\n",
    "        year_num = date_parts[1]\n",
    "        return year_num + '_' + month_num\n",
    "    return month_str\n",
    "\n",
    "\"\"\"\n",
    "Remove URLs from a text block\n",
    "\"\"\"\n",
    "no_url_re = re.compile('\\[?https?:\\/\\/.*[\\r\\n]*', flags=re.MULTILINE)\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(no_url_re, '', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(month_str2key('asdfasdf asdf asdf December 2013') == '2013_12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional function for easily batch scraping in the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch_queries(term_list, prefix_url, suffix_url, max_qlim = 48):\n",
    "    num_elems = len(term_list)\n",
    "    num_batches = num_elems / max_qlim\n",
    "    \n",
    "    batch_queries = []\n",
    "    for i in xrange(0, num_batches):\n",
    "        start_idx = i * max_qlim\n",
    "        end_idx = start_idx + max_qlim\n",
    "        query_str = prefix_url + \"|\".join(term_list[start_idx:end_idx]) + suffix_url\n",
    "        batch_queries.append(query_str)\n",
    "    batch_queries.append(prefix_url + \"|\".join(term_list[end_idx:num_elems]) + suffix_url)\n",
    "    \n",
    "    return batch_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Batch Scrape\n",
    "\n",
    "To avoid API call limits and throttling. Also makes queries faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of monthly death pages to be queried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create individual search terms for API query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "death_rep_words = 'Deaths_in_'\n",
    "mo_yr_elems = [death_rep_words + month + '_' + str(year) \n",
    "              for month in month_to_num.keys()\n",
    "              for year in year_list]\n",
    "mo_yr_elems.append('Deaths_in_January_2017')\n",
    "\n",
    "mo_yr_batch_queries = get_batch_queries(mo_yr_elems, mo_yr_url_prefix, mo_yr_url_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Wikipedia API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch queries to Wikipedia API stored as a list of results for each batch query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 823 ms, sys: 157 ms, total: 980 ms\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# query API\n",
    "mo_yr_batch_results = []\n",
    "\n",
    "for mo_yr_batch_query in mo_yr_batch_queries:\n",
    "    json_ret_val = requests.get(mo_yr_batch_query, headers=headers).json()\n",
    "    mo_yr_batch_results.append(json_ret_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpack query results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_contents = []\n",
    "\n",
    "for result in mo_yr_batch_results:\n",
    "    new_contents = [[page_result['title'], page_result['revisions'][0]['*']] \n",
    "                    for page_result in result['query']['pages'].values()]\n",
    "    q_contents.extend(new_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking queries into lists of summaries by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.57 s, sys: 134 ms, total: 1.71 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "q_contents_dict = {}\n",
    "\n",
    "for q_page in q_contents:\n",
    "    q_key = month_str2key(q_page[0])\n",
    "    q_list = [\n",
    "        add_month_year_list(\n",
    "            add_description_and_death(\n",
    "                parse_month_year_name_age(remove_urls(entry))),\n",
    "        q_key)\n",
    "        for entry in q_page[1].encode('utf-8').rstrip().split('*')\n",
    "        if re.match(name_age_re, entry.replace('\\n', ''))\n",
    "    ]\n",
    "    q_contents_dict[q_key] = q_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_entries = [entry for entry_list in q_contents_dict.values() for entry in entry_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55492, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>desc</th>\n",
       "      <th>cause_of_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Zvonko Bušić</td>\n",
       "      <td>67</td>\n",
       "      <td>Croatian airplane hijacker ([[TWA Flight 355]]...</td>\n",
       "      <td>suicide by gunshot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Joaquim Justino Carreira</td>\n",
       "      <td>63</td>\n",
       "      <td>Portuguese-born Brazilian Roman Catholic prela...</td>\n",
       "      <td>Bishop of [[Roman Catholic Diocese of Guarulh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Pál Csernai</td>\n",
       "      <td>80</td>\n",
       "      <td>Hungarian footballer and manager ([[FC Bayern ...</td>\n",
       "      <td>[[North Korea national football team|North Ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Ignacio Eizaguirre</td>\n",
       "      <td>92</td>\n",
       "      <td>Spanish footballer ([[Valencia CF|Valencia]], ...</td>\n",
       "      <td>[[Spain national football team|national team]]).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Ole Ernst</td>\n",
       "      <td>73</td>\n",
       "      <td>Danish actor.</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month                      name age  \\\n",
       "0  2013     9              Zvonko Bušić  67   \n",
       "1  2013     9  Joaquim Justino Carreira  63   \n",
       "2  2013     9               Pál Csernai  80   \n",
       "3  2013     9        Ignacio Eizaguirre  92   \n",
       "4  2013     9                 Ole Ernst  73   \n",
       "\n",
       "                                                desc  \\\n",
       "0  Croatian airplane hijacker ([[TWA Flight 355]]...   \n",
       "1  Portuguese-born Brazilian Roman Catholic prela...   \n",
       "2  Hungarian footballer and manager ([[FC Bayern ...   \n",
       "3  Spanish footballer ([[Valencia CF|Valencia]], ...   \n",
       "4                                      Danish actor.   \n",
       "\n",
       "                                      cause_of_death  \n",
       "0                                suicide by gunshot.  \n",
       "1   Bishop of [[Roman Catholic Diocese of Guarulh...  \n",
       "2   [[North Korea national football team|North Ko...  \n",
       "3   [[Spain national football team|national team]]).  \n",
       "4                                                     "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.DataFrame(all_entries)\n",
    "df_full.columns = ['year', 'month', 'name', 'age', 'desc', 'cause_of_death']\n",
    "print df_full.shape\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up (similar to old notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.95 s, sys: 132 ms, total: 5.09 s\n",
      "Wall time: 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_full['desc'] = df_full.desc.map(clean_text)\n",
    "df_full['cause_of_death'] = df_full.cause_of_death.map(clean_text)\n",
    "df_full['nationality'] = df_full.desc.map(get_nationality_text)\n",
    "df_full['name'] = df_full.name.map(get_wiki_url)\n",
    "\n",
    "df_full['desc'] = df_full.desc.map(clean_text)\n",
    "df_full['cause_of_death'] = df_full.cause_of_death.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55492, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>desc</th>\n",
       "      <th>cause_of_death</th>\n",
       "      <th>nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Zvonko Bušić</td>\n",
       "      <td>67</td>\n",
       "      <td>Croatian airplane hijacker (TWA Flight 355), s...</td>\n",
       "      <td>suicide by gunshot</td>\n",
       "      <td>Croatian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Joaquim Justino Carreira</td>\n",
       "      <td>63</td>\n",
       "      <td>Portuguese-born Brazilian Roman Catholic prela...</td>\n",
       "      <td>Bishop of Roman Catholic Diocese of Guarulhos ...</td>\n",
       "      <td>Portuguese-born Brazilian Roman Catholic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Pál Csernai</td>\n",
       "      <td>80</td>\n",
       "      <td>Hungarian footballer and manager (FC Bayern Mu...</td>\n",
       "      <td>North Korea national football team)</td>\n",
       "      <td>Hungarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Ignacio Eizaguirre</td>\n",
       "      <td>92</td>\n",
       "      <td>Spanish footballer (Valencia CF, Real Sociedad...</td>\n",
       "      <td>Spain national football team)</td>\n",
       "      <td>Spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>Ole Ernst</td>\n",
       "      <td>73</td>\n",
       "      <td>Danish actor</td>\n",
       "      <td></td>\n",
       "      <td>Danish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year month                      name age  \\\n",
       "0  2013     9              Zvonko Bušić  67   \n",
       "1  2013     9  Joaquim Justino Carreira  63   \n",
       "2  2013     9               Pál Csernai  80   \n",
       "3  2013     9        Ignacio Eizaguirre  92   \n",
       "4  2013     9                 Ole Ernst  73   \n",
       "\n",
       "                                                desc  \\\n",
       "0  Croatian airplane hijacker (TWA Flight 355), s...   \n",
       "1  Portuguese-born Brazilian Roman Catholic prela...   \n",
       "2  Hungarian footballer and manager (FC Bayern Mu...   \n",
       "3  Spanish footballer (Valencia CF, Real Sociedad...   \n",
       "4                                       Danish actor   \n",
       "\n",
       "                                      cause_of_death  \\\n",
       "0                                 suicide by gunshot   \n",
       "1  Bishop of Roman Catholic Diocese of Guarulhos ...   \n",
       "2                North Korea national football team)   \n",
       "3                      Spain national football team)   \n",
       "4                                                      \n",
       "\n",
       "                                nationality  \n",
       "0                                  Croatian  \n",
       "1  Portuguese-born Brazilian Roman Catholic  \n",
       "2                                 Hungarian  \n",
       "3                                   Spanish  \n",
       "4                                    Danish  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df_full.shape\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parentheses issue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_2_list = [df_full.columns.tolist()] + list(df_full.values.tolist())\n",
    "\n",
    "for row in full_2_list[1:]:\n",
    "    if len(row[5]) > 0:\n",
    "        if row[5][-1] == ')':\n",
    "            row[4] = row[4] + \", \" + row[5]\n",
    "            row[5] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../out/celeb_deaths_wikipedia_full_1.csv', 'wb') as df_full_2_outfile:\n",
    "    out_writer = csv.writer(df_full_2_outfile, delimiter=',')\n",
    "    for row in full_2_list:\n",
    "        out_writer.writerow(row)\n",
    "    df_full_2_outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting page size, date of birth, date of death, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55492"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names = list(df_full.name.map(lambda name: name.replace(' ','_')).values)\n",
    "len(all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_names_q = get_batch_queries(all_names, indiv_url_prefix, indiv_url_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1388"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_names_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'ns': 0, u'pageid': 10258809, u'revisions': [{u'size': 2579}], u'title': u'Roger Terry'}\n"
     ]
    }
   ],
   "source": [
    "print name_batch_results[66]['query']['pages'].values()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find remaining entries with missing page sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_info_current = pd.read_csv('../out/names_fame_birth_death_1.csv')\n",
    "names_wo_pg_size = names_info_current[names_info_current.page_size.map(lambda val: np.isnan(val))]\n",
    "batch_names_q = get_batch_queries(list(names_wo_pg_size.name.values), indiv_url_prefix, indiv_url_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_names_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Wikipedia for page sizes. For 136 queries (x48 terms/query ~= 6500 queries), takes about 4min 30sec (270 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 1 - 2 - 3 - 4 - 5 - 6 - 7 - 8 - 9 - 10 - 11 - 12 - 13 - 14 - 15 - 16 - 17 - 18 - 19 - 20 - 21 - 22 - 23 - 24 - 25 - 26 - 27 - 28 - 29 - 30 - 31 - 32 - 33 - 34 - 35 - 36 - 37 - 38 - 39 - 40 - 41 - 42 - 43 - 44 - 45 - 46 - 47 - 48 - 49 - 50 - 51 - 52 - 53 - 54 - 55 - 56 - 57 - 58 - 59 - 60 - 61 - 62 - 63 - 64 - 65 - 66 - 67 - 68 - 69 - 70 - 71 - 72 - 73 - 74 - 75 - 76 - 77 - 78 - 79 - 80 - 81 - 82 - 83 - 84 - 85 - 86 - 87 - 88 - 89 - 90 - 91 - 92 - 93 - 94 - 95 - 96 - 97 - 98 - 99 - 100 - 101 - 102 - 103 - 104 - 105 - 106 - 107 - 108 - 109 - 110 - 111 - 112 - 113 - 114 - 115 - 116 - 117 - 118 - 119 - 120 - 121 - 122 - 123 - 124 - 125 - 126 - 127 - 128 -CPU times: user 4.24 s, sys: 311 ms, total: 4.55 s\n",
      "Wall time: 4min 22s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "counter = 0\n",
    "\n",
    "# query API\n",
    "name_batch_results = []\n",
    "\n",
    "for batch in batch_names_q:\n",
    "    ret_val = requests.get(batch, headers=headers)\n",
    "    # print json_ret_val\n",
    "    try:\n",
    "        json_ret_val = ret_val.json()\n",
    "        name_batch_results.append(json_ret_val)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    print counter, \"-\",\n",
    "    counter += 1\n",
    "\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_q_contents = []\n",
    "\n",
    "for result in name_batch_results:\n",
    "    for page_result in result['query']['pages'].values():\n",
    "        if 'revisions' in page_result.keys():\n",
    "            size_info = page_result['revisions']\n",
    "            new_contents = [page_result['title'], page_result['revisions'][0]['size']]\n",
    "            names_q_contents.append(new_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5952"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names_q_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save new page sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../out/names_fame_birth_death_1_rem.csv', 'wb') as remaining_outfile:\n",
    "    csv_rem_writer = csv.writer(remaining_outfile, delimiter=',')\n",
    "    for row in names_q_contents:\n",
    "        csv_rem_writer.writerow(row)\n",
    "    remaining_outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
